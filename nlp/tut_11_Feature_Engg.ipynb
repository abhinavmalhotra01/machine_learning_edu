{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Dru1n_iwEnjH"
      },
      "outputs": [],
      "source": [
        "# features -> represent text as a vector \n",
        "# vectors -> we can assign several features for each word -> used for classification\n",
        "# each feature can have a binary/decimal value associated to it -> 1,0,...\n",
        "# example -> there are 2 features -> location , person -> example -> dhoni -> person : 1 , location : 0\n",
        "# this can be represented in a form of a vector -> [1,0] ; associated with ['person','location']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# called text representation\n",
        "# representing text as vector -> vector space model\n",
        "# approaches to convert into vector \n",
        "# 1. one hot encoding\n",
        "# 2. bag of words\n",
        "# 3. Tf-Idf\n",
        "# 4. Word embedding\n",
        "# 5. Label Encoding"
      ],
      "metadata": {
        "id": "rzGNlmiqGFTx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Label and One Hot Encoding***"
      ],
      "metadata": {
        "id": "a8pQZnhGGoqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLP -> raw Text => Vector => ML\n",
        "\n",
        "# label encoding -> similar to ml categorical vars\n",
        "# one hot encoding -> \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "# in NLP , people dont use -> disadv :\n",
        "# doesnt capture meaning of word \n",
        "# very much memory required to store many columns if number of unique words high \n",
        "# no fixed length representation \n"
      ],
      "metadata": {
        "id": "P-4x-1ZTGm7B"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Bag Of Words***"
      ],
      "metadata": {
        "id": "SMW5txLSIQQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# col of unique words -> each row -> each doc -> each [row][col] -> number of occurences of col's label in doc of row"
      ],
      "metadata": {
        "id": "BT1KxWWkIYIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first build vocabulary -> containing unique words -> representing cols\n",
        "# limitations -> if words very much : much memory"
      ],
      "metadata": {
        "id": "i-WEJmWIJBe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "goZNpE2LJWcy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"spam.csv\")"
      ],
      "metadata": {
        "id": "4rUbUfzJJhT8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rWlzuQnKJjtA",
        "outputId": "a1391889-ff84-4ea1-e93d-fbc2e3fabac1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Category                                            Message\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b7e2846-93d1-41f5-8bdf-a2ba5f08b033\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b7e2846-93d1-41f5-8bdf-a2ba5f08b033')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b7e2846-93d1-41f5-8bdf-a2ba5f08b033 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b7e2846-93d1-41f5-8bdf-a2ba5f08b033');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.Category.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IopsoTRCJ_yb",
        "outputId": "c3451ea4-6320-40db-c10f-2ffab5d361eb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ham     4825\n",
              "spam     747\n",
              "Name: Category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding spam , ham\n",
        "df['spam']=df['Category'].apply(lambda x : 1 if x=='spam' else 0)"
      ],
      "metadata": {
        "id": "Hu95gvLtKrGS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "C6e4MF3RK7sF",
        "outputId": "ac0d79d6-4529-4526-aeac-43ac395ea0e3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Category                                            Message  spam\n",
              "0      ham  Go until jurong point, crazy.. Available only ...     0\n",
              "1      ham                      Ok lar... Joking wif u oni...     0\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
              "3      ham  U dun say so early hor... U c already then say...     0\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...     0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e15421b-652a-47ce-9290-8e9f99a8d399\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e15421b-652a-47ce-9290-8e9f99a8d399')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9e15421b-652a-47ce-9290-8e9f99a8d399 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9e15421b-652a-47ce-9290-8e9f99a8d399');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train , X_test , y_train , y_test = train_test_split(df.Message,df.spam,test_size=0.2)"
      ],
      "metadata": {
        "id": "weOfV-_WLADk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWDI2S4FLGoW",
        "outputId": "6867202d-9363-4812-c17c-8de76fd7e05b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1279    Can i meet ü at 5.. As 4 where depends on wher...\n",
              "52      K fyi x has a ride early tomorrow morning but ...\n",
              "825                             Have a good evening! Ttyl\n",
              "3037                     ;-) ok. I feel like john lennon.\n",
              "1729    As per your request 'Maangalyam (Alaipayuthe)'...\n",
              "Name: Message, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovXj4sohLezq",
        "outputId": "8ce33ba8-6b26-4c1f-8c6a-4483bfe1a843"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4457,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa5d2CpMLioF",
        "outputId": "ca515a3c-a681-4603-cfed-85aa8e8eae89"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1115,)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dDOB0bOLkCQ",
        "outputId": "5321b907-0f67-43e3-db16-c59dafea804c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPVh733qLnQQ",
        "outputId": "d843c320-da05-4abb-87d3-cb111798e9ab"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# building bag of words model ->\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "X_train_cv = cv.fit_transform(X_train.values)\n",
        "X_train_cv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkdUuCwuLvKw",
        "outputId": "0e7cac18-bba3-47df-c30c-55fd2a6911fb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4457x7784 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 59810 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_cv.toarray()[:2][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFw-8GqUL_Ow",
        "outputId": "c6f49865-1caa-4f51-e2a0-56e4cba903d1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_cv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhNR8tztMSeR",
        "outputId": "6359619f-58fb-4443-c066-98f37efdc86a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4457, 7784)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSWVFJ8CMVKy",
        "outputId": "4d7873ec-b34c-48b7-c6ab-1df43fe3ef17"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'can': 1647,\n",
              " 'meet': 4461,\n",
              " 'at': 1124,\n",
              " 'as': 1093,\n",
              " 'where': 7523,\n",
              " 'depends': 2272,\n",
              " 'on': 4973,\n",
              " 'wan': 7411,\n",
              " 'in': 3674,\n",
              " 'lor': 4249,\n",
              " 'fyi': 3085,\n",
              " 'has': 3372,\n",
              " 'ride': 5824,\n",
              " 'early': 2526,\n",
              " 'tomorrow': 6989,\n",
              " 'morning': 4625,\n",
              " 'but': 1589,\n",
              " 'he': 3396,\n",
              " 'crashing': 2080,\n",
              " 'our': 5046,\n",
              " 'place': 5270,\n",
              " 'tonight': 6998,\n",
              " 'have': 3387,\n",
              " 'good': 3211,\n",
              " 'evening': 2686,\n",
              " 'ttyl': 7096,\n",
              " 'ok': 4958,\n",
              " 'feel': 2828,\n",
              " 'like': 4152,\n",
              " 'john': 3870,\n",
              " 'lennon': 4117,\n",
              " 'per': 5189,\n",
              " 'your': 7754,\n",
              " 'request': 5764,\n",
              " 'maangalyam': 4327,\n",
              " 'alaipayuthe': 902,\n",
              " 'been': 1298,\n",
              " 'set': 6076,\n",
              " 'callertune': 1632,\n",
              " 'for': 2970,\n",
              " 'all': 919,\n",
              " 'callers': 1631,\n",
              " 'press': 5438,\n",
              " 'to': 6966,\n",
              " 'copy': 2031,\n",
              " 'friends': 3037,\n",
              " 'famous': 2792,\n",
              " 'quote': 5580,\n",
              " 'when': 7519,\n",
              " 'you': 7750,\n",
              " 'develop': 2299,\n",
              " 'the': 6844,\n",
              " 'ability': 757,\n",
              " 'listen': 4186,\n",
              " 'anything': 1009,\n",
              " 'unconditionally': 7169,\n",
              " 'without': 7591,\n",
              " 'losing': 4253,\n",
              " 'temper': 6791,\n",
              " 'or': 5014,\n",
              " 'self': 6040,\n",
              " 'confidence': 1978,\n",
              " 'it': 3795,\n",
              " 'means': 4450,\n",
              " 'are': 1057,\n",
              " 'married': 4402,\n",
              " 'knock': 3992,\n",
              " 'txt': 7123,\n",
              " 'whose': 7539,\n",
              " 'there': 6861,\n",
              " '80082': 644,\n",
              " 'enter': 2632,\n",
              " 'weekly': 7479,\n",
              " 'draw': 2461,\n",
              " '250': 362,\n",
              " 'gift': 3159,\n",
              " 'voucher': 7366,\n",
              " 'store': 6536,\n",
              " 'of': 4932,\n",
              " 'yr': 7765,\n",
              " 'choice': 1821,\n",
              " 'cs': 2113,\n",
              " 'www': 7683,\n",
              " 'tkls': 6952,\n",
              " 'com': 1923,\n",
              " 'age16': 868,\n",
              " 'stoptxtstop': 6535,\n",
              " '50': 540,\n",
              " 'week': 7476,\n",
              " 'yeah': 7723,\n",
              " 'sure': 6654,\n",
              " 'll': 4203,\n",
              " 'leave': 4100,\n",
              " 'min': 4520,\n",
              " 'shall': 6102,\n",
              " 'come': 1928,\n",
              " 'get': 3144,\n",
              " 'pickle': 5243,\n",
              " 'no': 4835,\n",
              " 'plans': 5281,\n",
              " 'yet': 7737,\n",
              " 'what': 7512,\n",
              " 'doing': 2416,\n",
              " 'said': 5922,\n",
              " 'not': 4870,\n",
              " 'now': 4883,\n",
              " 'problem': 5470,\n",
              " 'let': 4126,\n",
              " 'me': 4444,\n",
              " 'know': 3994,\n",
              " 'sms': 6301,\n",
              " 'ac': 774,\n",
              " 'sptv': 6452,\n",
              " 'new': 4798,\n",
              " 'jersey': 3855,\n",
              " 'devils': 2302,\n",
              " 'and': 972,\n",
              " 'detroit': 2297,\n",
              " 'red': 5685,\n",
              " 'wings': 7569,\n",
              " 'play': 5284,\n",
              " 'ice': 3618,\n",
              " 'hockey': 3494,\n",
              " 'correct': 2035,\n",
              " 'incorrect': 3688,\n",
              " 'end': 2607,\n",
              " 'reply': 5757,\n",
              " 'lil': 4158,\n",
              " 'fever': 2844,\n",
              " 'fine': 2882,\n",
              " 'ya': 7709,\n",
              " 'srsly': 6459,\n",
              " 'better': 1338,\n",
              " 'than': 6829,\n",
              " 'yi': 7740,\n",
              " 'tho': 6889,\n",
              " 'hi': 3456,\n",
              " 'always': 941,\n",
              " 'online': 4982,\n",
              " 'yahoo': 7711,\n",
              " 'would': 7653,\n",
              " 'chat': 1763,\n",
              " 'with': 7587,\n",
              " 'someday': 6336,\n",
              " 'welp': 7493,\n",
              " 'apparently': 1027,\n",
              " 'retired': 5801,\n",
              " 'my': 4708,\n",
              " 'uncles': 7167,\n",
              " 'atlanta': 1128,\n",
              " 'wish': 7579,\n",
              " 'guys': 3313,\n",
              " 'great': 3264,\n",
              " 'semester': 6047,\n",
              " 'cool': 2026,\n",
              " 'text': 6816,\n",
              " 'few': 2845,\n",
              " 'anyway': 1012,\n",
              " 'don': 2425,\n",
              " 'think': 6875,\n",
              " 'secure': 6021,\n",
              " 'up': 7216,\n",
              " 'here': 3443,\n",
              " 'lemme': 4114,\n",
              " 'if': 3634,\n",
              " 'want': 7415,\n",
              " 'drive': 2475,\n",
              " 'down': 2449,\n",
              " 'south': 6382,\n",
              " 'chill': 1807,\n",
              " 'love': 4269,\n",
              " 'both': 1453,\n",
              " 'too': 7002,\n",
              " 'every': 2692,\n",
              " 'monday': 4606,\n",
              " 'nxt': 4908,\n",
              " 'vl': 7353,\n",
              " 'be': 1276,\n",
              " 'completing': 1959,\n",
              " 'day': 2196,\n",
              " 'pray': 5410,\n",
              " 'remove': 5737,\n",
              " 'teeth': 6776,\n",
              " 'its': 3803,\n",
              " 'painful': 5094,\n",
              " 'maintaining': 4362,\n",
              " 'other': 5039,\n",
              " 'stuff': 6574,\n",
              " 'objection': 4919,\n",
              " 'bf': 1346,\n",
              " 'coming': 1934,\n",
              " 'hey': 3453,\n",
              " 'tmr': 6960,\n",
              " 'bugis': 1562,\n",
              " '930': 730,\n",
              " 'urgent': 7239,\n",
              " 'please': 5292,\n",
              " 'call': 1622,\n",
              " '0906346330': 196,\n",
              " 'abta': 770,\n",
              " 'complimentary': 1960,\n",
              " 'spanish': 6391,\n",
              " 'holiday': 3504,\n",
              " '10': 247,\n",
              " '000': 1,\n",
              " 'cash': 1693,\n",
              " 'await': 1171,\n",
              " 'collection': 1916,\n",
              " 'sae': 5915,\n",
              " 'box': 1463,\n",
              " '47': 503,\n",
              " 'po19': 5308,\n",
              " '2ez': 384,\n",
              " '150ppm': 304,\n",
              " '18': 317,\n",
              " 'dont': 2429,\n",
              " 'say': 5965,\n",
              " 'that': 6840,\n",
              " 'gonna': 3209,\n",
              " 'death': 2212,\n",
              " 'note': 4871,\n",
              " 'says': 5969,\n",
              " 'robs': 5850,\n",
              " 'fault': 2813,\n",
              " 'avenge': 1164,\n",
              " 'need': 4770,\n",
              " 'ke': 3941,\n",
              " 'qi': 5562,\n",
              " 'bored': 1445,\n",
              " 'izzit': 3812,\n",
              " 'suddenly': 6607,\n",
              " 'thk': 6883,\n",
              " 'this': 6882,\n",
              " 'we': 7452,\n",
              " 'pay': 5159,\n",
              " 'over': 5065,\n",
              " 'lt': 4290,\n",
              " 'gt': 3288,\n",
              " 'yrs': 7766,\n",
              " 'so': 6320,\n",
              " 'difficult': 2335,\n",
              " 'may': 4435,\n",
              " 'later': 4066,\n",
              " 'pls': 5300,\n",
              " 'hope': 3526,\n",
              " 'arnt': 1078,\n",
              " 'pissed': 5263,\n",
              " 'off': 4934,\n",
              " 'id': 3623,\n",
              " 'really': 5646,\n",
              " 'see': 6024,\n",
              " 'xxxxxxxxxxxxxx': 7706,\n",
              " 'hmm': 3488,\n",
              " 'ill': 3647,\n",
              " 'about': 761,\n",
              " 're': 5627,\n",
              " 'forgiven': 2980,\n",
              " 'these': 6863,\n",
              " 'won': 7615,\n",
              " 'do': 2395,\n",
              " 'move': 4642,\n",
              " 'morphine': 4627,\n",
              " 'own': 5077,\n",
              " 'oga': 4951,\n",
              " 'left': 4106,\n",
              " 'phone': 5226,\n",
              " 'home': 3509,\n",
              " 'just': 3908,\n",
              " 'saw': 5964,\n",
              " 'ur': 7235,\n",
              " 'messages': 4494,\n",
              " 'weekend': 7477,\n",
              " 'actually': 813,\n",
              " 'deleted': 2250,\n",
              " 'old': 4966,\n",
              " 'website': 7467,\n",
              " 'blogging': 1402,\n",
              " 'magicalsongs': 4351,\n",
              " 'blogspot': 1403,\n",
              " 'yar': 7715,\n",
              " 'quite': 5576,\n",
              " 'fast': 2805,\n",
              " 'cos': 2039,\n",
              " 'da': 2159,\n",
              " 'ge': 3126,\n",
              " 'slow': 6272,\n",
              " 'wat': 7432,\n",
              " 'haha': 3325,\n",
              " 'else': 2588,\n",
              " 'sorts': 6371,\n",
              " 'funny': 3079,\n",
              " 'things': 6874,\n",
              " 'omg': 4971,\n",
              " 'could': 2050,\n",
              " 'snow': 6315,\n",
              " 'tonite': 6999,\n",
              " 'housewives': 3556,\n",
              " 'date': 2189,\n",
              " '0871750': 127,\n",
              " '77': 628,\n",
              " '11': 261,\n",
              " 'bt': 1549,\n",
              " 'national': 4746,\n",
              " 'rate': 5612,\n",
              " '10p': 258,\n",
              " 'only': 4984,\n",
              " 'from': 3050,\n",
              " 'landlines': 4044,\n",
              " 'keep': 3942,\n",
              " 'raining': 5593,\n",
              " 'non': 4850,\n",
              " 'stop': 6528,\n",
              " 'go': 3188,\n",
              " 'elsewhere': 2589,\n",
              " 'planning': 5280,\n",
              " 'chennai': 1787,\n",
              " 'pass': 5138,\n",
              " 'dis': 2359,\n",
              " 'contacts': 2004,\n",
              " 'luv': 4305,\n",
              " 'wid': 7546,\n",
              " 'blue': 1415,\n",
              " 'put': 5553,\n",
              " 'smile': 6289,\n",
              " 'face': 2770,\n",
              " 'purple': 5546,\n",
              " 'realy': 5648,\n",
              " 'hot': 3545,\n",
              " 'pink': 5259,\n",
              " 'swt': 6694,\n",
              " 'orange': 5018,\n",
              " 'thnk': 6886,\n",
              " 'lyk': 4314,\n",
              " 'green': 3268,\n",
              " 'wana': 7413,\n",
              " 'out': 5049,\n",
              " 'yelow': 7730,\n",
              " 'wnt': 7607,\n",
              " 'bck': 1266,\n",
              " 'black': 1383,\n",
              " 'jealous': 3843,\n",
              " 'brown': 1538,\n",
              " 'miss': 4547,\n",
              " 'nw': 4907,\n",
              " 'plz': 5304,\n",
              " 'giv': 3170,\n",
              " 'one': 4978,\n",
              " 'color': 1919,\n",
              " 'today': 6973,\n",
              " 'sunday': 6632,\n",
              " 'is': 3783,\n",
              " 'work': 7633,\n",
              " 'wow': 7657,\n",
              " 'didn': 2323,\n",
              " 'was': 7426,\n",
              " 'common': 1939,\n",
              " 'take': 6718,\n",
              " 'back': 1198,\n",
              " 'freak': 3012,\n",
              " 'unless': 7200,\n",
              " 'chop': 1825,\n",
              " 'haf': 3324,\n",
              " 'lunch': 4301,\n",
              " 'canteen': 1661,\n",
              " 'thanks': 6833,\n",
              " 'tescos': 6809,\n",
              " 'nice': 4809,\n",
              " 'gone': 3207,\n",
              " 'speak': 6397,\n",
              " 'soon': 6358,\n",
              " 'swimming': 6688,\n",
              " 'pool': 5347,\n",
              " 'jacuzzi': 3820,\n",
              " 'house': 3554,\n",
              " 'sis': 6224,\n",
              " 'catching': 1702,\n",
              " 'show': 6169,\n",
              " 'afternoon': 860,\n",
              " 'watching': 7436,\n",
              " 'her': 3442,\n",
              " 'watch': 7433,\n",
              " 'ready': 5638,\n",
              " 'inches': 3678,\n",
              " 'pleasure': 5295,\n",
              " 'sent': 6061,\n",
              " 'cant': 1659,\n",
              " 'display': 2377,\n",
              " 'texts': 6826,\n",
              " 'still': 6517,\n",
              " 'send': 6051,\n",
              " 'his': 3474,\n",
              " 'number': 4897,\n",
              " 'yup': 7772,\n",
              " 'fren': 3026,\n",
              " 'meeting': 4463,\n",
              " '730': 619,\n",
              " 'lol': 4227,\n",
              " 'right': 5825,\n",
              " 'diet': 2329,\n",
              " 'everyday': 2696,\n",
              " 'cheat': 1770,\n",
              " 'meant': 4451,\n",
              " 'fatty': 2812,\n",
              " 'person': 5202,\n",
              " 'give': 3171,\n",
              " 'na': 4719,\n",
              " 'sorry': 6366,\n",
              " 'ten': 6793,\n",
              " 'rs': 5881,\n",
              " 'shelf': 6120,\n",
              " 'buy': 1594,\n",
              " 'two': 7122,\n",
              " 'egg': 2564,\n",
              " 'armand': 1073,\n",
              " 'ass': 1111,\n",
              " 'epsilon': 2651,\n",
              " 'looks': 4242,\n",
              " 'wrong': 7668,\n",
              " 'kappa': 3930,\n",
              " 'numbers': 4898,\n",
              " 'him': 3467,\n",
              " 'around': 1079,\n",
              " 'supposed': 6651,\n",
              " 'discuss': 2371,\n",
              " 'abt': 769,\n",
              " 'trip': 7068,\n",
              " 'thought': 6894,\n",
              " 'xuhui': 7696,\n",
              " 'told': 6981,\n",
              " 'lesson': 4124,\n",
              " 'after': 859,\n",
              " 'busy': 1588,\n",
              " 'by': 1606,\n",
              " 'some': 6333,\n",
              " 'point': 5327,\n",
              " 'figure': 2861,\n",
              " 'aight': 885,\n",
              " 'got': 3228,\n",
              " 'then': 6855,\n",
              " 'going': 3199,\n",
              " 'wif': 7548,\n",
              " 'family': 2791,\n",
              " 'aft': 858,\n",
              " 'dat': 2188,\n",
              " 'str': 6541,\n",
              " 'orchard': 5021,\n",
              " 'big': 1355,\n",
              " 'difference': 2333,\n",
              " 'versus': 7308,\n",
              " 'hrs': 3570,\n",
              " 'collecting': 1915,\n",
              " 'laptop': 4053,\n",
              " 'configure': 1979,\n",
              " 'settings': 6078,\n",
              " 'shopping': 6152,\n",
              " 'paid': 5092,\n",
              " '2004': 342,\n",
              " 'account': 790,\n",
              " '07xxxxxxxxx': 44,\n",
              " 'shows': 6175,\n",
              " '786': 631,\n",
              " 'unredeemed': 7207,\n",
              " 'points': 5328,\n",
              " 'claim': 1843,\n",
              " '08719181259': 148,\n",
              " 'identifier': 3629,\n",
              " 'code': 1899,\n",
              " 'xxxxx': 7703,\n",
              " 'expires': 2747,\n",
              " '26': 366,\n",
              " '03': 15,\n",
              " '05': 17,\n",
              " 'wil': 7554,\n",
              " 'minutes': 4539,\n",
              " 'any': 1001,\n",
              " 'space': 6386,\n",
              " 'yep': 7732,\n",
              " 'derek': 2279,\n",
              " 'makes': 4365,\n",
              " 'fall': 2786,\n",
              " 'prone': 5500,\n",
              " 'falls': 2789,\n",
              " 'lucky': 4297,\n",
              " 'dad': 2163,\n",
              " 'ask': 1101,\n",
              " 'fetch': 2842,\n",
              " 'already': 932,\n",
              " 'trying': 7087,\n",
              " 'contact': 2002,\n",
              " 'last': 4060,\n",
              " 'weekends': 7478,\n",
              " '900': 725,\n",
              " 'prize': 5465,\n",
              " 'guaranteed': 3292,\n",
              " '09061701939': 186,\n",
              " 's89': 5908,\n",
              " 'valid': 7279,\n",
              " '12hrs': 282,\n",
              " 'hanging': 3351,\n",
              " 'brother': 1535,\n",
              " 'juz': 3914,\n",
              " 'accordin': 788,\n",
              " 'discussed': 2372,\n",
              " 'yest': 7735,\n",
              " 'except': 2721,\n",
              " 'kb': 3940,\n",
              " 'sun': 6630,\n",
              " 'nt': 4889,\n",
              " 'much': 4674,\n",
              " 'attend': 1135,\n",
              " 'sat': 5951,\n",
              " 'same': 5935,\n",
              " 'thing': 6873,\n",
              " 'everyso': 2699,\n",
              " 'often': 4950,\n",
              " 'panicks': 5105,\n",
              " 'starts': 6486,\n",
              " 'goin': 3198,\n",
              " 'bout': 1459,\n",
              " 'bein': 1314,\n",
              " 'enough': 2630,\n",
              " 'pick': 5240,\n",
              " 'happened': 3355,\n",
              " 'cruise': 2109,\n",
              " 'care': 1673,\n",
              " 'free': 3017,\n",
              " 'ringtone': 5834,\n",
              " 'waiting': 7395,\n",
              " 'collected': 1914,\n",
              " 'simply': 6208,\n",
              " 'password': 5144,\n",
              " 'mix': 4562,\n",
              " '85069': 683,\n",
              " 'verify': 7305,\n",
              " 'usher': 7260,\n",
              " 'britney': 1526,\n",
              " 'fml': 2945,\n",
              " 'po': 5307,\n",
              " '5249': 555,\n",
              " 'mk17': 4565,\n",
              " '92h': 729,\n",
              " '450ppw': 499,\n",
              " '16': 312,\n",
              " 'yes': 7734,\n",
              " 'princess': 5455,\n",
              " 'make': 4364,\n",
              " 'happy': 3362,\n",
              " 'glad': 3175,\n",
              " 'talking': 6728,\n",
              " 'tell': 6782,\n",
              " 'reached': 5630,\n",
              " 'beautiful': 1283,\n",
              " 'truth': 7084,\n",
              " 'against': 865,\n",
              " 'gravity': 3260,\n",
              " 'read': 5634,\n",
              " 'carefully': 1679,\n",
              " 'heart': 3412,\n",
              " 'feels': 2833,\n",
              " 'light': 4148,\n",
              " 'someone': 6337,\n",
              " 'very': 7309,\n",
              " 'heavy': 3417,\n",
              " 'leaves': 4101,\n",
              " 'goodmorning': 3215,\n",
              " 'em': 2591,\n",
              " 'find': 2879,\n",
              " 'wtc': 7673,\n",
              " 'far': 2801,\n",
              " 'weiyi': 7489,\n",
              " 'rest': 5789,\n",
              " 'dunno': 2510,\n",
              " 'dinner': 2350,\n",
              " 'den': 2261,\n",
              " 'might': 4511,\n",
              " 'able': 760,\n",
              " 'join': 3871,\n",
              " 'goldviking': 3203,\n",
              " '29': 375,\n",
              " 'inviting': 3760,\n",
              " 'friend': 3036,\n",
              " '762': 625,\n",
              " 'frnd': 3043,\n",
              " '62468': 583,\n",
              " 'am': 943,\n",
              " 'late': 4063,\n",
              " 'decimal': 2221,\n",
              " 'why': 7541,\n",
              " 'didnt': 2324,\n",
              " 'holla': 3505,\n",
              " 'b4u': 1186,\n",
              " '27': 369,\n",
              " 'marsms': 4404,\n",
              " 'log': 4220,\n",
              " 'onto': 4986,\n",
              " 'b4utele': 1187,\n",
              " 'discount': 2369,\n",
              " 'credit': 2090,\n",
              " 'opt': 5009,\n",
              " 'customer': 2144,\n",
              " '08717168528': 125,\n",
              " 'sec': 6011,\n",
              " 'breaking': 1503,\n",
              " 'cstore': 2117,\n",
              " 'valued': 7283,\n",
              " 'pleased': 5293,\n",
              " 'advise': 843,\n",
              " 'following': 2954,\n",
              " 'recent': 5666,\n",
              " 'review': 5811,\n",
              " 'mob': 4580,\n",
              " 'awarded': 1175,\n",
              " '1500': 299,\n",
              " 'bonus': 1432,\n",
              " '09066364589': 221,\n",
              " 'well': 7492,\n",
              " 'quality': 5566,\n",
              " 'aint': 887,\n",
              " 'bad': 1201,\n",
              " 'complaining': 1952,\n",
              " 'local': 4214,\n",
              " 'dates': 2191,\n",
              " 'area': 1058,\n",
              " 'lots': 4258,\n",
              " 'people': 5187,\n",
              " 'registered': 5708,\n",
              " 'start': 6483,\n",
              " 'flirtparty': 2927,\n",
              " 'us': 7250,\n",
              " 'replys150': 5759,\n",
              " 'darlin': 2182,\n",
              " 'im': 3651,\n",
              " 'missin': 4549,\n",
              " 'having': 3393,\n",
              " 'time': 6931,\n",
              " 'jess': 3856,\n",
              " 'xx': 7697,\n",
              " 'result': 5796,\n",
              " 'luckily': 4296,\n",
              " 'starring': 6480,\n",
              " 'role': 5856,\n",
              " 'arrived': 1086,\n",
              " 'couple': 2058,\n",
              " 'days': 2197,\n",
              " 'meh': 4467,\n",
              " 'thgt': 6870,\n",
              " 'will': 7558,\n",
              " 'clash': 1850,\n",
              " 'ah': 877,\n",
              " 'dun': 2508,\n",
              " 'mind': 4523,\n",
              " 'seen': 6032,\n",
              " 'lost': 4255,\n",
              " 'weight': 7483,\n",
              " 'gee': 3127,\n",
              " 'worry': 7644,\n",
              " 'nothing': 4875,\n",
              " 'money': 4608,\n",
              " 'use': 7254,\n",
              " 'completely': 1957,\n",
              " 'form': 2985,\n",
              " 'clark': 1848,\n",
              " 'also': 935,\n",
              " 'utter': 7267,\n",
              " 'waste': 7429,\n",
              " 'whats': 7514,\n",
              " 'again': 864,\n",
              " 'beer': 1300,\n",
              " 'had': 3323,\n",
              " 'sapna': 5943,\n",
              " 'aunty': 1150,\n",
              " 'manege': 4382,\n",
              " 'hogidhe': 3495,\n",
              " 'chinnu': 1814,\n",
              " 'full': 3068,\n",
              " 'weak': 7453,\n",
              " 'swalpa': 6672,\n",
              " 'agidhane': 873,\n",
              " 'gud': 3294,\n",
              " 'ni8': 4807,\n",
              " 'drms': 2480,\n",
              " 'how': 3559,\n",
              " 'working': 7636,\n",
              " 'short': 6154,\n",
              " 'cute': 2149,\n",
              " 'try': 7085,\n",
              " 'prove': 5511,\n",
              " 'mrng': 4653,\n",
              " 'does': 2404,\n",
              " 'dance': 2172,\n",
              " 'river': 5844,\n",
              " 'salad': 5924,\n",
              " 'desert': 2283,\n",
              " 'something': 6342,\n",
              " 'many': 4387,\n",
              " 'beers': 1301,\n",
              " 'top': 7010,\n",
              " 'polyphonic': 5341,\n",
              " 'tones': 6992,\n",
              " '087018728737': 75,\n",
              " 'toppoly': 7013,\n",
              " 'tune': 7105,\n",
              " 'subpoly': 6586,\n",
              " '81618': 657,\n",
              " 'pole': 5332,\n",
              " 'unsub': 7211,\n",
              " '08718727870': 142,\n",
              " 'an': 969,\n",
              " 'acknowledgement': 797,\n",
              " 'astoundingly': 1120,\n",
              " 'tactless': 6712,\n",
              " 'generally': 3133,\n",
              " 'faggy': 2778,\n",
              " 'demand': 2260,\n",
              " 'blood': 1408,\n",
              " 'oath': 4916,\n",
              " 'fo': 2947,\n",
              " 'another': 990,\n",
              " '6hrs': 608,\n",
              " 'sleep': 6254,\n",
              " 'pain': 5093,\n",
              " 'surgical': 6658,\n",
              " 'emergency': 2598,\n",
              " 'unfolds': 7184,\n",
              " 'okay': 4959,\n",
              " 'scores': 5986,\n",
              " 'sophas': 6363,\n",
              " 'secondary': 6013,\n",
              " 'application': 1032,\n",
              " 'schools': 5980,\n",
              " 'thinking': 6877,\n",
              " 'applying': 1034,\n",
              " 'research': 5768,\n",
              " 'cost': 2041,\n",
              " 'joke': 3874,\n",
              " 'ogunrinde': 4952,\n",
              " 'school': 5979,\n",
              " 'less': 4122,\n",
              " 'expensive': 2743,\n",
              " 'ones': 4979,\n",
              " 'joy': 3889,\n",
              " 'father': 2809,\n",
              " 'name': 4727,\n",
              " 'mandan': 4380,\n",
              " 'open': 4995,\n",
              " 'goodnight': 3216,\n",
              " 'pa': 5082,\n",
              " 'takin': 6722,\n",
              " 'shower': 6171,\n",
              " 'done': 2427,\n",
              " 'fighting': 2858,\n",
              " 'world': 7639,\n",
              " 'easy': 2537,\n",
              " 'either': 2573,\n",
              " 'win': 7561,\n",
              " 'lose': 4251,\n",
              " 'fightng': 2859,\n",
              " 'some1': 6334,\n",
              " 'who': 7533,\n",
              " 'close': 1868,\n",
              " 'dificult': 2337,\n",
              " '22': 353,\n",
              " 'kick': 3961,\n",
              " 'euro2004': 2679,\n",
              " 'kept': 3948,\n",
              " 'latest': 4067,\n",
              " 'news': 4802,\n",
              " 'results': 5797,\n",
              " 'daily': 2167,\n",
              " 'removed': 5738,\n",
              " '83222': 668,\n",
              " 'jane': 3828,\n",
              " 'babes': 1193,\n",
              " 'wrk': 7665,\n",
              " 'lst': 4289,\n",
              " 'nite': 4829,\n",
              " 'foned': 2959,\n",
              " 'cover': 2065,\n",
              " 'chuck': 1834,\n",
              " 'cousin': 2064,\n",
              " 'chinese': 1812,\n",
              " 'food': 2961,\n",
              " 'way': 7447,\n",
              " 'fat': 2808,\n",
              " 'paying': 5165,\n",
              " 'lipo': 4181,\n",
              " 'sir': 6222,\n",
              " 'chance': 1742,\n",
              " 'reality': 5643,\n",
              " 'fantasy': 2800,\n",
              " '08707509020': 84,\n",
              " '20p': 349,\n",
              " 'ntt': 4892,\n",
              " 'ltd': 4291,\n",
              " '1327': 286,\n",
              " 'croydon': 2105,\n",
              " 'cr9': 2071,\n",
              " '5wb': 570,\n",
              " '0870': 68,\n",
              " 'special': 6398,\n",
              " 'increase': 3689,\n",
              " 'winning': 7571,\n",
              " 'timing': 6935,\n",
              " 'double': 2443,\n",
              " 'mins': 4535,\n",
              " 'price': 5448,\n",
              " 'linerental': 4169,\n",
              " 'bluetooth': 1416,\n",
              " 'mobiles': 4583,\n",
              " 'mobileupd8': 4586,\n",
              " 'offers': 4942,\n",
              " '08000839402': 49,\n",
              " 'call2optout': 1624,\n",
              " 'lf56': 4131,\n",
              " 'daddy': 2164,\n",
              " 'scream': 5995,\n",
              " 'slap': 6252,\n",
              " 'dick': 2318,\n",
              " 'audrie': 1144,\n",
              " 'lousy': 4266,\n",
              " 'autocorrect': 1155,\n",
              " 'cramps': 2076,\n",
              " 'stopped': 6533,\n",
              " 'finished': 2887,\n",
              " 'wake': 7396,\n",
              " 'idea': 3625,\n",
              " 'guess': 3298,\n",
              " 'hour': 3551,\n",
              " 'since': 6211,\n",
              " 'usual': 7264,\n",
              " 'nobody': 4838,\n",
              " 'interest': 3740,\n",
              " 'figuring': 2863,\n",
              " 'shit': 6136,\n",
              " 'before': 1303,\n",
              " 'second': 6012,\n",
              " 'went': 7497,\n",
              " 'project': 5488,\n",
              " 'centre': 1726,\n",
              " 'unsubscribed': 7213,\n",
              " 'services': 6073,\n",
              " 'tons': 7000,\n",
              " 'sexy': 6088,\n",
              " 'hunks': 3591,\n",
              " 'straight': 6543,\n",
              " 'http': 3573,\n",
              " 'gotbabes': 3231,\n",
              " 'co': 1890,\n",
              " 'uk': 7152,\n",
              " 'subscriptions': 6595,\n",
              " 'wont': 7622,\n",
              " 'de': 2202,\n",
              " 'eat': 2538,\n",
              " 'maggi': 4348,\n",
              " 'mee': 4460,\n",
              " 'wait': 7392,\n",
              " 'getting': 3152,\n",
              " 'bridgwater': 1514,\n",
              " 'banter': 1229,\n",
              " 'hello': 3427,\n",
              " 'goes': 3195,\n",
              " 'babe': 1192,\n",
              " 'job': 3865,\n",
              " 'prospects': 5509,\n",
              " 'boytoy': 1484,\n",
              " 'teasing': 6770,\n",
              " 'kiss': 3980,\n",
              " 'wot': 7649,\n",
              " 'bitch': 1376,\n",
              " 'eating': 2541,\n",
              " 'plate': 5282,\n",
              " 'leftovers': 4107,\n",
              " 'alone': 929,\n",
              " '2nd': 403,\n",
              " 'tried': 7067,\n",
              " '400': 475,\n",
              " '087104711148': 90,\n",
              " 'minute': 4538,\n",
              " 've': 7297,\n",
              " 'blake': 1386,\n",
              " 'address': 822,\n",
              " 'occurs': 4928,\n",
              " 'sell': 6043,\n",
              " 'knowing': 3995,\n",
              " 'company': 1945,\n",
              " 'message': 4492,\n",
              " 'blackberry': 1384,\n",
              " 'bold2': 1428,\n",
              " 'nigeria': 4815,\n",
              " 'funk': 3077,\n",
              " 'fone': 2958,\n",
              " 'tone': 6991,\n",
              " 'tones2u': 6993,\n",
              " 'ringtones': 5836,\n",
              " 'original': 5032,\n",
              " 'best': 1333,\n",
              " '3gbp': 460,\n",
              " 'network': 4790,\n",
              " 'operator': 5001,\n",
              " 'rates': 5613,\n",
              " 'apply': 1033,\n",
              " 'outside': 5058,\n",
              " 'islands': 3789,\n",
              " 'head': 3397,\n",
              " 'towards': 7029,\n",
              " 'hard': 3363,\n",
              " 'rock': 5851,\n",
              " 'run': 5898,\n",
              " 'into': 3749,\n",
              " 'men': 4481,\n",
              " 'shorter': 6158,\n",
              " 'ladies': 4029,\n",
              " 'gaze': 3121,\n",
              " 'eyes': 2765,\n",
              " 'slept': 6261,\n",
              " 'tel': 6778,\n",
              " 'should': 6163,\n",
              " 'mistake': 4555,\n",
              " 'senthil': 6063,\n",
              " 'hsbc': 3571,\n",
              " 'todays': 6974,\n",
              " '800': 640,\n",
              " '09050001808': 161,\n",
              " 'land': 4040,\n",
              " 'line': 4166,\n",
              " 'm95': 4325,\n",
              " 'valid12hrs': 7280,\n",
              " 'wen': 7494,\n",
              " 'lovable': 4268,\n",
              " 'bcums': 1273,\n",
              " 'angry': 977,\n",
              " 'dnt': 2394,\n",
              " 'seriously': 6069,\n",
              " 'coz': 2068,\n",
              " 'being': 1315,\n",
              " 'most': 4630,\n",
              " 'childish': 1802,\n",
              " 'true': 7078,\n",
              " 'showing': 6172,\n",
              " 'deep': 2231,\n",
              " 'affection': 850,\n",
              " 'kettoda': 3952,\n",
              " 'manda': 4379,\n",
              " 'height': 3422,\n",
              " 'oh': 4953,\n",
              " 'situation': 6232,\n",
              " 'guy': 3312,\n",
              " 'throws': 6908,\n",
              " 'letter': 4128,\n",
              " 'gal': 3093,\n",
              " 'brothers': 1536,\n",
              " 'whos': 7538,\n",
              " 'gay': 3118,\n",
              " 'excellent': 2720,\n",
              " 'misundrstud': 4557,\n",
              " 'knw': 3998,\n",
              " 'hate': 3378,\n",
              " 'urself': 7249,\n",
              " 'gn': 3184,\n",
              " 'uncle': 7166,\n",
              " 'informed': 3707,\n",
              " 'directly': 2354,\n",
              " 'walk': 7400,\n",
              " 'julianaland': 3900,\n",
              " 'oblivious': 4922,\n",
              " 'constantly': 2001,\n",
              " 'they': 6868,\n",
              " 'ear': 2523,\n",
              " 'while': 7529,\n",
              " 'whatever': 7513,\n",
              " 'upset': 7231,\n",
              " 'surprised': 6662,\n",
              " 'mad': 4337,\n",
              " 'presnts': 5437,\n",
              " 'bcz': 1274,\n",
              " 'mis': 4543,\n",
              " 'jeevithathile': 3845,\n",
              " 'irulinae': 3782,\n",
              " 'neekunna': 4777,\n",
              " 'prakasamanu': 5403,\n",
              " 'sneham': 6310,\n",
              " 'prakasam': 5402,\n",
              " 'ennal': 2629,\n",
              " 'prabha': 5394,\n",
              " 'mns': 4575,\n",
              " 'congrats': 1986,\n",
              " 'year': 7724,\n",
              " 'cinema': 1838,\n",
              " 'yours': 7758,\n",
              " '09061209465': 179,\n",
              " 'suprman': 6652,\n",
              " 'matrix3': 4424,\n",
              " 'starwars3': 6487,\n",
              " 'etc': 2674,\n",
              " 'bx420': 1604,\n",
              " 'ip4': 3766,\n",
              " '5we': 571,\n",
              " '150pm': 302,\n",
              " 'waking': 7397,\n",
              " 'until': 7215,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_np = X_train_cv.toarray()\n",
        "X_train_np[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSJsqXhsMl0k",
        "outputId": "481b74ba-94a7-4168-e915-a709fc8efa60"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.where(X_train_np[0]!=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBMLILqAM1u2",
        "outputId": "a26f7977-2d3f-4e36-b18a-3bd47dd9d201"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1093, 1124, 1647, 2272, 3674, 4249, 4461, 4973, 7411, 7523]),)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # building model ->\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_cv,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "17ojDC5lM9Z4",
        "outputId": "2fe4ed57-380b-450e-90de-845f53795f2e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv.transform(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Woaku5bTNd8u",
        "outputId": "d2808be3-7dfa-48da-c5ad-a63e828eb07d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1115x7784 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 13290 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_cv = cv.transform(X_test)"
      ],
      "metadata": {
        "id": "BLFgHheVNlD7"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(X_test_cv)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNIX6OQiNphF",
        "outputId": "5635b3f6-145c-4d7b-fa87-b47c3719d1f4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       981\n",
            "           1       0.96      0.95      0.95       134\n",
            "\n",
            "    accuracy                           0.99      1115\n",
            "   macro avg       0.98      0.97      0.97      1115\n",
            "weighted avg       0.99      0.99      0.99      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hue hue , greamt accuramcy "
      ],
      "metadata": {
        "id": "0D7Mhh20N2f6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# easier way , using sklearn pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "clf = Pipeline([\n",
        "    ('vectorizer',CountVectorizer()),\n",
        "    ('nb',MultinomialNB())\n",
        "])\n",
        "# pipeline is simply a api"
      ],
      "metadata": {
        "id": "u1GR70tLOH7L"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "L16EzL-sOZmV",
        "outputId": "121edc3c-49ec-4f0d-e2e4-275c19818518"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer', CountVectorizer()), ('nb', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()), (&#x27;nb&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()), (&#x27;nb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred2 = clf.predict(X_test)\n",
        "print(classification_report(y_test,y_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl1TMtj2OcCl",
        "outputId": "8d084e86-bfcd-488a-ab3a-393f5cb21bda"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       981\n",
            "           1       0.96      0.95      0.95       134\n",
            "\n",
            "    accuracy                           0.99      1115\n",
            "   macro avg       0.98      0.97      0.97      1115\n",
            "weighted avg       0.99      0.99      0.99      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Smol Exercise"
      ],
      "metadata": {
        "id": "99vvRg8veOmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(\"IMDB_Dataset.csv\",engine=\"python\",\n",
        "error_bad_lines=False,)\n",
        "df2.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "16-hFAFHOjXE",
        "outputId": "efe6c4a1-26c8-4f5e-b01b-50d452e866e6"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-72-54e37cc5f740>:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df2 = pd.read_csv(\"IMDB_Dataset.csv\",engine=\"python\",\n",
            "Skipping line 19011: unexpected end of data\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b558d47d-3830-486e-a659-4de8a3dac74a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b558d47d-3830-486e-a659-4de8a3dac74a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b558d47d-3830-486e-a659-4de8a3dac74a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b558d47d-3830-486e-a659-4de8a3dac74a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df2.review, df2.sentiment, test_size=0.2)"
      ],
      "metadata": {
        "id": "aTPS0zScjMpt"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf2 = Pipeline([\n",
        "    ('vectorizer',CountVectorizer()),\n",
        "    ('rf',RandomForestClassifier(n_estimators=50,criterion='entropy'))\n",
        "])"
      ],
      "metadata": {
        "id": "AutAP0qseYsN"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf2.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "GdhBnvbghkaX",
        "outputId": "4900e289-aa65-460c-e03d-6b037f7a2774"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
              "                ('rf',\n",
              "                 RandomForestClassifier(criterion='entropy', n_estimators=50))])"
            ],
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
              "                (&#x27;rf&#x27;,\n",
              "                 RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=50))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
              "                (&#x27;rf&#x27;,\n",
              "                 RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=50))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=50)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_1 = clf2.predict(X_test)\n",
        "print(classification_report(y_test,y_pred_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWDQ3yTYh0_A",
        "outputId": "e6b00ee4-28e0-40a9-ad8d-6f72fb231b92"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.84      0.84      1968\n",
            "    positive       0.83      0.83      0.83      1834\n",
            "\n",
            "    accuracy                           0.84      3802\n",
            "   macro avg       0.84      0.84      0.84      3802\n",
            "weighted avg       0.84      0.84      0.84      3802\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "clf3 = Pipeline([\n",
        "    ('vectoriz',CountVectorizer()),\n",
        "    ('knn',KNeighborsClassifier(n_neighbors=10,metric='euclidean'))\n",
        "])"
      ],
      "metadata": {
        "id": "q9nFHYShh7eT"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf3.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "P-l4GDvNiQhY",
        "outputId": "e1229d33-039c-4e3f-bddf-58542d6618e8"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectoriz', CountVectorizer()),\n",
              "                ('knn',\n",
              "                 KNeighborsClassifier(metric='euclidean', n_neighbors=10))])"
            ],
            "text/html": [
              "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectoriz&#x27;, CountVectorizer()),\n",
              "                (&#x27;knn&#x27;,\n",
              "                 KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectoriz&#x27;, CountVectorizer()),\n",
              "                (&#x27;knn&#x27;,\n",
              "                 KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=10)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_2 = clf3.predict(X_test)\n",
        "print(classification_report(y_test,y_pred_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17XYf4C4iUiH",
        "outputId": "ce286fca-d992-4080-c6e4-d1460bd64e8f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.66      0.65      0.66      1968\n",
            "    positive       0.63      0.64      0.64      1834\n",
            "\n",
            "    accuracy                           0.65      3802\n",
            "   macro avg       0.65      0.65      0.65      3802\n",
            "weighted avg       0.65      0.65      0.65      3802\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf4 = Pipeline([\n",
        "    ('vec',CountVectorizer()),\n",
        "    ('nb',MultinomialNB())\n",
        "])"
      ],
      "metadata": {
        "id": "SOM6QT9hiepi"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf4.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "omGaX16GivzV",
        "outputId": "ca26c7af-bec4-4ca6-9ade-b41cd70dccc5"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vec', CountVectorizer()), ('nb', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vec&#x27;, CountVectorizer()), (&#x27;nb&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vec&#x27;, CountVectorizer()), (&#x27;nb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_3 = clf4.predict(X_test)"
      ],
      "metadata": {
        "id": "StOxkntGiyUR"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,y_pred_3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBF4NVxpi2Mr",
        "outputId": "ae50262a-6bde-4541-bc1e-d73f1ace038a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.87      0.86      1968\n",
            "    positive       0.86      0.82      0.84      1834\n",
            "\n",
            "    accuracy                           0.85      3802\n",
            "   macro avg       0.85      0.85      0.85      3802\n",
            "weighted avg       0.85      0.85      0.85      3802\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this process, we convert text into a very high dimensional numeric vector using the technique of Bag of words.\n",
        "\n",
        "Model like K-Nearest Neighbours(KNN) doesn't work well with high dimensional data because with large number of dimensions, it becomes difficult for the algorithm to calculate distance in each dimension. In higher dimensional space, the cost to calculate distance becomes expensive and hence impacts the performance of model."
      ],
      "metadata": {
        "id": "weQsORArk7c7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x8jKGjjdi5L6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}